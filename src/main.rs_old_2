use rscam::{Camera, Config, CID_JPEG_COMPRESSION_QUALITY};
use std::fs::File;
use std::io;
// use std::io::prelude::*;
use std::cmp::{min, max};
// use ndarray::{Array2, Array3, arr3, Axis};
// use ndarray::prelude::*;
use tokio::runtime::Runtime;
use tokio::task;
// use image::*;
use serde::Deserialize;
use chrono::Local;
use std::time;
use jpeg_decoder::Decoder;
use async_std::future;

#[derive(Debug, Deserialize)]
struct Settings {
    width: u32,
    height: u32,
    device: String,
    format: String,
    output_dir: String,
    threshold: i16,
    frame_diff_div: u32,
    delay: u64,
    debug: bool
}

struct Pixels<'a, T: std::marker::Copy> {
    width: usize,
    height: usize,
    data: &'a Vec<T>
}

impl<'a, T: std::marker::Copy> Pixels<'a, T> {
    fn new(width: usize, height:usize, data: &Vec<T>) -> Pixels<T> {
        Pixels{width: width, height: height, data: data}
    }
    fn get(self: &Self, x: usize, y:usize) -> T {
        self.data[x + y * self.width]
    }
}

struct Kernel<T: std::marker::Copy> {
    data: [T; 9]
}

impl<T: std::marker::Copy> Kernel<T> {
    fn get(self: &Self, x: usize, y:usize) -> T {
        self.data[x + y * 3]
    }
}

const k0: Kernel::<i16> = Kernel::<i16>{data: [-1,0,1,-2,0,2,-1,0,1]};
const k1: Kernel::<i16> = Kernel::<i16>{data: [1,2,1,0,0,0,-1,-2,-1]};

// trait Indexing2D {
//     type Element;
//     fn get(self, x: usize, y:usize) -> Self::Element;
// }

// impl<'a, T: std::marker::Copy> Indexing2D for Pixels<'a, T> {
//     type Element = T;
//     fn get(self, x: usize, y:usize) -> Self::Element {
//         self.data[x + y * self.width]
//     }
// }

// fn get_kernels() -> Array3<i16> {
//     arr3(&[
//         [
//             [-1,0,1],
//             [-2,0,2],
//             [-1,0,1]
//         ],
//         [
//             [1,2,1],
//             [0,0,0],
//             [-1,-2,-1]
//         ]
//     ])
// }

// fn get_kernels<'a>() -> Vec<Pixels<'a, i16>> {
//     return vec!(
//         Pixels::<i16>::new(3,3,&k0.to_vec()),
//         Pixels::<i16>::new(3,3,&k1.to_vec())
//     )
// }

// fn get_image(camera: &Camera) -> Vec<u8> {
//     let frame = camera.capture().expect("Can't access frame!");
//     // let decoder = jpeg::JpegDecoder::<&[u8]>::new(&*frame).expect("Can't create decoder!");
//     // let mut r = decoder.into_reader().expect("Can't create reader!");
//     // let mut reader = TimeoutReader::new(r, Duration::from_seconds(2));
//     // let mut buffer = Vec::new();
//     // reader.read_to_end(&mut buffer);
//     let mut decoder = Decoder::new(&*frame);
//     let buffer = decoder.decode().expect("Can't decode jpeg!");

//     return buffer
// }

fn decode_jpeg(frame: rscam::Frame) -> Vec::<u8> {
    let mut decoder = Decoder::new(&*frame);
    let buffer = decoder.decode().expect("Can't decode jpeg!");

    return buffer
}

// fn gray_blur(input: &Vec<u8>, width: u32, height: u32) -> Vec<u8> {
//     let mut gray = Vec::<u8>::new();
//     let mut idx = 0;
//     while idx<input.len() {
//         gray.push(input[idx]/3+input[idx+1]/3+input[idx+2]/3);
//         idx += 3;
//     }

//     let mut v = Vec::<u8>::new();
//     let arr = Array2::from_shape_vec((height as usize, width as usize), gray).unwrap();

//     for x in 1..arr.shape()[0]-1 {
//         for y in 1..arr.shape()[1]-1 {
//             v.push((
//                 arr[[x-1,y]] as f64/5.0 +
//                 arr[[x+1,y]] as f64/5.0 +
//                 arr[[x,y-1]] as f64/5.0 +
//                 arr[[x,y+1]] as f64/5.0 +
//                 arr[[x,y]] as f64/5.0
//             ) as u8)
//         }
//     }
//     return v
// }

fn to_grayscale(input: &Vec<u8>,) -> Vec<u8> {
    let mut gray = vec![0; input.len()/3];
    let mut idx = 0;
    while idx<input.len() {
        gray[idx/3] = input[idx]/3+input[idx+1]/3+input[idx+2]/3;
        idx += 3;
    };
    return gray
}

// fn sobel(input: &Vec<u8>, width: u32, height: u32, kernels: &Array3<i16>, threshold: i16) -> Vec::<u8> {
//     let mut v = Vec::<u8>::new();
//     let arr = Array2::from_shape_vec((height as usize, width as usize), input.to_owned()).unwrap();
//     // let mut sum = 0;

//     for x in 1..arr.shape()[0]-1 {
//         for y in 1..arr.shape()[1]-1 {
//             let mut value: i16 = 0;
//             for k in 0..1 {
//                 let kernel = kernels.index_axis(Axis(0), k);
//                 for wx in 0..=2 {
//                     for wy in 0..=2 {
//                         value += arr[[x+wx-1, y+wy-1]] as i16 * kernel[[wx,wy]];
//                     }
//                 }
//             }
//             if value.abs() < threshold { v.push(0)} else {v.push(255)};
//             // if value.abs() > threshold { sum+= 1 };
//         }
//     };
//     v
// }

// fn blur(input: &Vec<u8>, width: u32, height: u32) -> Vec::<u8> {
//     let mut v = Vec::<u8>::new();
//     //let pixels = Pixels::<u8>::new(width as usize, height as usize, input);
//     let arr = Array2::from_shape_vec((height as usize, width as usize), input.to_owned()).unwrap();

//     for x in 0..height as isize{
//         for y in 0..width as isize{
//             let mut value: f32 = 0.0;
//             let mut count: f32 = 0.0;
//             for wy in max(0,y-1)..min(height as isize,y+1) {
//                 for wx in max(0,x-1)..min(width as isize,x+1) {
//                     count += 1.0;
//                     value + arr[[wx as usize, wy as usize]] as f32;
//                 }
//             }
//             v.push((value / count) as u8);
//         }
//     }
//     return v
// }

fn blur(input: &Vec<u8>, width: u32, height: u32) -> Vec::<u8> {
    let mut v = Vec::<u8>::new();
    let pixels = Pixels::<u8>::new(width as usize, height as usize, input);

    for y in 0..height as isize{
        for x in 0..width as isize{
            let mut value: f32 = 0.0;
            let mut count: f32 = 0.0;
            for wy in max(0,y-1)..min(height as isize,y+1) {
                for wx in max(0,x-1)..min(width as isize,x+1) {
                    count += 1.0;
                    value += pixels.get(wx as usize,wy as usize) as f32;
                }
            }
            v.push((value / count) as u8);
        }
    }
    return v
}

fn sobel(input: &Vec<u8>, width: u32, height: u32, kernels: &Vec<Kernel<i16>>, threshold: i16) -> Vec::<u8> {
    let mut v = Vec::<u8>::new();
    let pixels = Pixels::<u8>::new(width as usize, height as usize, input);

    for y in 0..height as isize{
        for x in 0..width as isize{
            let mut value: i16 = 0;

             for k in kernels.iter() {
                 for wy in max(0,y-1)..min(height as isize,y+1) {
                    for wx in max(0,x-1)..min(width as isize,x+1) {
                         value += pixels.get((wx) as usize, (wy) as usize) as i16 * k.get((x-wx+1) as usize, (y-wy+1) as usize);
                     }
                 }
             }
             if value.abs() < threshold { v.push(0)} else {v.push(255)};
        }
    }
    return v
}

// async fn capture(camera: &rscam::Camera) -> rscam::Frame {
//     let d = time::Duration::from_secs(1);
//     match future::timeout(d, camera.capture()) {
//         Ok(r) => {
//         },
//         _ => {
//         }
//     }
// }

fn main() {
    let file = File::open("settings.json").expect("Settings file not found!");
    let reader = io::BufReader::new(file);

    let settings: Settings = serde_json::from_reader(reader).expect("Settings cannot be parsed!");
    println!("{:?}", settings);
    let frame_thresh = (settings.width * settings.height / settings.frame_diff_div) as i16;
    if settings.debug {println!("Thresh sum: {}", frame_thresh)};

    let mut camera = Camera::new(&settings.device).unwrap();
    camera.set_control(CID_JPEG_COMPRESSION_QUALITY, &95);

    camera.start(&Config {
        interval: (1, 30),
        resolution: (settings.width, settings.height),
        format: settings.format.as_bytes(),
        ..Default::default()
    }).unwrap();

    let kernels = vec!(k0, k1);

    // let gray = to_grayscale(&get_image(&camera, settings.width, settings.height));
    // let img_blur = blur(&gray, settings.width, settings.height);
    // let buf = sobel(&img_blur, settings.width, settings.height, &kernels, settings.threshold);
    // let img = GrayImage::from_raw(settings.width, settings.height, buf).unwrap();
    // img.save("sobel.png");

    // return;

    let mut last: Vec::<u8> = vec!(0; (settings.width * settings.height) as usize);
    
    loop {
        let loop_start = time::Instant::now();
        let mut runtime = Runtime::new().unwrap();
        
        // let frame = camera.capture().expect("Can't access frame!");
        // let blurred = gray_blur(&buf, settings.width, settings.height);
        // let cur = sobel(&blurred, (settings.width-2) as usize, (settings.height-2) as usize, &kernels, settings.threshold);
        // let mut frame: &rscam::Frame;
        // let mut buf;
        let cam_ref = &camera;
        let frame_result = runtime.block_on(async move {
            task::spawn_blocking(move || {
                cam_ref.capture().expect("Can't access frame!")
            }).await
        });

        runtime.shutdown_timeout(time::Duration::from_secs(1));
        let frame;
        match frame_result {
            Ok(r) => {frame = r}
            _ => {
                println!("Restarting camera");
                camera.stop();
                *cam_ref.start(&Config {
                    interval: (1, 30),
                    resolution: (settings.width, settings.height),
                    format: settings.format.as_bytes(),
                    ..Default::default()
                }).unwrap();
                continue;
            }
        }

        // let frame = camera.capture().expect("Can't access frame!");

        //let gray = to_grayscale(&decode_jpeg(frame));
        // let blurred = blur(&gray, settings.width, settings.height);
        let buf = decode_jpeg(frame);
        let gray = to_grayscale(&buf);
        let cur = sobel(&gray, settings.width, settings.height, &kernels, settings.threshold);

        // let mut diff = Vec::<u8>::new();

        let mut sum = 0;
        for idx in 0..cur.len() {
            // if cur[idx] > last[idx] { diff.push(cur[idx]-last[idx]) } else { diff.push(last[idx]-cur[idx]) };
            if cur[idx] != last[idx] {sum+=1};
        }

        last = cur;

        
        // for idx in 0..diff.len() {
        //     if diff[idx]>0 {sum+=1}
        // }

        if sum > frame_thresh {
            println!("Movement detected. {}", sum);
            // let img = RgbImage::from_raw(settings.width, settings.height, buf).expect("Can't create RGB image!");
            // let path = format!("{}output_{}.png", settings.output_dir, Local::now().format("%Y%m%d_%H_%M_%S"));
            // if settings.debug {println!("Saving to: {}", path)};
            // img.save(path).expect("Cannot save image file!");

            // let diff_img = GrayImage::from_raw(settings.width, settings.height, diff).unwrap();
            // diff_img.save("diff.png");
        }
        let elapsed = time::Instant::now() - loop_start;
        if settings.debug { println!("Diff sum: {}, elapsed: {:?}", sum, elapsed)};
        // thread::sleep(time::Duration::from_millis(settings.delay) - elapsed);
    }
}